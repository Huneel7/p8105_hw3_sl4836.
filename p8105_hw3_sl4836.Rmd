---
title: "p8105_hw3_sl4836"
author: "Hun"
date: "10/16/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
```

### ggplot theme template from Dr.Goldsmith github
```{r, warning=FALSE, message=FALSE, echo=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 0
```{r, warning=FALSE, message=FALSE}
getwd()

dir.create(file.path(getwd(), "HW3_data_file"), recursive = TRUE)

list.files()
```

### Problem 1_Import Data and Data_Summary
```{r, warning=FALSE, message=FALSE}
library(p8105.datasets)
data("instacart")
```

### Problem 1_Data_Summary
```{r, warning=FALSE, message=FALSE}
instacart <- instacart 

instacart %>% head

instacart_names <- names(instacart)
instacart_nrow <- nrow(instacart)
instacart_ncol <- ncol(instacart)
```
The size of the dataset is **`r instacart_nrow` x**  **`r instacart_ncol`** and **`r instacart_ncol`** variables: *`r instacart_names`.* There are **`r instacart_nrow`** number of observations without missing data. Among these, there are 4 character variables and 11 numeric variables. 


### Problem 1_(a)_Answering how many aisles are there, and which aisles are the most items ordered from.
```{r, warning=FALSE, message=FALSE}
Arranged_aisles <- 
  instacart %>% 
  group_by(aisle) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

number_aisles <- 
  nrow(Arranged_aisles)

top_3_item <- 
  Arranged_aisles %>% 
  mutate(aisle = str_to_title(aisle)) %>% 
  pull(aisle) %>%
  head(3)

top_item <- 
  Arranged_aisles %>% 
  mutate(aisle = str_to_title(aisle)) %>% 
  pull(aisle) %>%
  first()
```
There are **`r number_aisles`** aisles. Among them, top 3 aisles that have the most ordered items are **`r top_3_item`.** It follows that **`r top_item`** has the largest number of ordered items. 

### Problem 1_(b)_Making a plot that shows the number of items ordered in each aisle
```{r, warning=FALSE, message=FALSE}
Arranged_aisles %>% 
  filter(n>10000) %>%
  ggplot(aes(x = reorder(aisle, n), y = n)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  labs(y = "Number of Items", 
       x = "Aisles", 
       title = "The Number of Items Ordered in Each Aisle",
       subtitle = "From aisles that have at least more than 10,000 items") +
  theme(axis.text.y = element_text(size =7.5, face="bold"))

```

This plot shows the number of items ordered in each aisles with at least 10,000 items in a descending order. As aforementioned from the previous part, fresh vegetables aisle has the largest number of items, followed by fresh fruits aisle, packaged vegetables fruits aisle, yogurt aisle, etc. 




### Problem 1_(c)_making a table showing the three most popular items in each aisles

```{r, warning=FALSE, message=FALSE}
options(knitr.kable.NA = 0)

baking_top3 <- instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "baking ingredients")

dog_food_top3 <- instacart %>% 
  filter(aisle == "dog food care") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "dog food care")

packaged_vege_fruit_top3 <- instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  group_by(product_name) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3) %>%
  mutate(aisle = "packaged vegetables fruits")

bind_rows(baking_top3 ,
          dog_food_top3, 
          packaged_vege_fruit_top3)  %>%
    mutate(aisle = str_to_title(aisle)) %>%
  rename(Aisle = aisle) %>%
  knitr::kable(align = "c", format = "pipe", 
               caption = "**Table 1: Three Most Popular Items 
               with their counts in Each Aisles**")
```
This table shows three most popular items with their counts in eash Aisles. In Baking Ingredients aisle, **light brown sugar, pure baking soda, and cande sugar** are top 3 popular items. In Dog Food Care aisle, **snack sticks chicken & rice recipe dog treats, organix chicken & brown rice recipe, and small dog biscuits** are top 3 popular items. In Packaged Vegetables Fruits aisle, **organic baby spinach, organic raspberries, and organic blueberries** are top 3 popular items.

### Problem 1_(d)_Making a table showing the mean hour of the day
```{r, warning=FALSE, message=FALSE}
instacart %>% 
  filter(product_name == "Pink Lady Apples" |product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>%
  rename(Product_Name = product_name) %>%
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>%
  knitr::kable(align = "c", format = "pipe",
               caption = "**The Mean Hour of the Day at which
               Each Item is Ordered on Each Day**"
               )
  
```
This tables shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. For Coffee Ice Cream, Day 2 has the longest mean hour whereas Day 5 has the least mean hour. For Pink Lady Apples, Day 3 has the longest mean hour whereas Day 1 has least mean hour. 

### Problem 2_Data Import
```{r, warning=FALSE, message=FALSE}
data("brfss_smart2010") 
```

### Problem 2_(a)_Data_Cleaning
```{r, warning=FALSE, message=FALSE}
brfss <- brfss_smart2010 


brfss_clean <- brfss %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent", "Very good",
                         "Good","Fair", "Poor" )) %>%
  mutate(response = as.factor(response) %>% 
           fct_relevel("Poor", "Fair", "Good", "Very good",
                       "Excellent")) 

```



After filtering Overall Health level solely from Topic variable, I included responses from Excellent to Poor. And then I re-leveled the response variable from Poor to Excellent.

### Problem 2_(b)_Showing States observed at 7 or more observations in 2002
```{r, warning=FALSE, message=FALSE}

brfss_clean_2002 <-
  brfss_clean %>% 
  rename(States = locationabbr) %>%
  filter(year == 2002) %>% 
  group_by(States) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n)

brfss_clean_2002_States <- brfss_clean_2002 %>% pull(States)  
brfss_clean_2002 %>% knitr::kable()



```

 **`r brfss_clean_2002_States`** are the states that were observed at 7 or more observations in 2002. 

### Problem 2_(b)_Showing States observed at 7 or more observations in 2010
```{r, warning=FALSE, message=FALSE}
brfss_clean_2010 <-
  brfss_clean %>% 
  rename(States = locationabbr) %>%
  filter(year == 2010) %>%
  group_by(States) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
  filter(n >= 7) %>%
  arrange(n) 
  
  
brfss_clean_2010_States <- brfss_clean_2010 %>% pull(States)  
brfss_clean_2010 %>% knitr::kable()
  

```
 **`r brfss_clean_2010_States`** are the states that were observed at 7 or more observations in 2010. 


### Problem 2_(c)_Making a spaghetti plot of BRFSS data average value over time within a state 
```{r, warning=FALSE, message=FALSE}
brfss_clean %>% 
  filter(response == "Excellent") %>%
  rename(States = locationabbr) %>%
  group_by(year, States) %>%
  summarise(mean_data_value = mean(data_value, na.rm=T)) %>% 
  ggplot(aes(year, mean_data_value, color=States)) + 
  geom_point(size=0.2) + 
  geom_line(aes(group=States), alpha=0.5) +
  labs(y = "Average Value", x = "Year") +
  theme(legend.position = "right", legend.title =
          element_text(colour="black", size=10, face="bold"), 
        legend.key.size = unit(0.5, 'cm')) 
 

```

This is a spaghetti plot that shows a line of the average BRFSS data value over time within a state from 2002 to 2010. It appears that the average values are relatively high in 2002 across states. 


### Problem 2_(d)_Making the distribution of BRFSS data_value for responses in 2006 and 2010
```{r, warning=FALSE, message=FALSE}
library(ggridges)

brfss_clean %>% 
  filter(year == 2006 | year == 2010, locationabbr == "NY") %>%
  group_by(locationdesc) %>%
  ggplot(aes(response, data_value, color = response)) +
  geom_boxplot() +
  facet_wrap(.~year) + 
  ggtitle("Distribution of data_value for responses in NY State") +
  labs(x = "Levels of Response", y = "BRFSS Data Value") +
  scale_color_discrete(name="Levels of Response:") +
  theme(axis.text.x = element_text(size=8))
```

This twp-panel plot shows the distribution of BRFSS data value for responses from Poor to Excellent in 2006 and 2010. It appears that there is a similar overall trend between 2006 and 2010, but the distribution of data value is quite different within response levels between 2006 and 2010. 

